{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90222a4b",
   "metadata": {},
   "source": [
    "# ðŸ¤– Deep Learning: ANN & CNN\n",
    "\n",
    "This notebook trains:\n",
    "\n",
    "- A simple ANN baseline\n",
    "- A 1D CNN model\n",
    "- Score binning and calibration-style plots\n",
    "- Score combination (ensemble-like composite score)\n",
    "\n",
    "> Important: because `bad` is rare (~2.35%), accuracy can be misleading. Prefer AUC, PR-AUC, recall/precision, and calibrated risk curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c6b26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb06c015",
   "metadata": {},
   "source": [
    "## Load engineered dataset\n",
    "\n",
    "This notebook expects:\n",
    "- `df_fe` (features + `bad`)\n",
    "- or load from disk (recommended)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6890b794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you saved df_fe earlier:\n",
    "# df_fe = pd.read_parquet(DATA_DIR + \"df_fe.parquet\")\n",
    "\n",
    "df_fe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0004d825",
   "metadata": {},
   "source": [
    "## Train/test split and scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812a53f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = df_fe.drop(columns=[\"bad\"])\n",
    "y = df_fe[\"bad\"].astype(int).to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.30, random_state=0, stratify=y\n",
    ")\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test  = sc.transform(X_test)\n",
    "\n",
    "# reshape for 1D CNN: (samples, timesteps/features, channels)\n",
    "X_train_cnn = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test_cnn  = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "X_train.shape, X_train_cnn.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47822065",
   "metadata": {},
   "source": [
    "## 1) ANN baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d59902",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "ann = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(units=X_train.shape[1], activation=\"relu\", input_dim=X_train.shape[1]),\n",
    "    tf.keras.layers.Dense(units=6, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(units=1, activation=\"sigmoid\"),\n",
    "])\n",
    "\n",
    "ann.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\n",
    "    \"accuracy\",\n",
    "    tf.keras.metrics.AUC(name=\"auc\"),\n",
    "    tf.keras.metrics.AUC(name=\"pr_auc\", curve=\"PR\"),\n",
    "])\n",
    "\n",
    "ann.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f117ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_ann = ann.fit(X_train, y_train, batch_size=256, epochs=10, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8dca71e",
   "metadata": {},
   "source": [
    "### Evaluate ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83e0604",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_eval = ann.evaluate(X_test, y_test, verbose=0)\n",
    "dict(zip(ann.metrics_names, ann_eval))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9161b2ac",
   "metadata": {},
   "source": [
    "## 2) 1D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40e8c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv1D(filters=32, kernel_size=2, padding=\"same\", activation=\"relu\", input_shape=(X_train.shape[1], 1)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPool1D(pool_size=2),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "\n",
    "    tf.keras.layers.Conv1D(filters=64, kernel_size=2, padding=\"same\", activation=\"relu\"),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPool1D(pool_size=2),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(units=64, activation=\"relu\"),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(units=1, activation=\"sigmoid\"),\n",
    "])\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "cnn.compile(optimizer=opt, loss=\"binary_crossentropy\", metrics=[\n",
    "    \"accuracy\",\n",
    "    tf.keras.metrics.AUC(name=\"auc\"),\n",
    "    tf.keras.metrics.AUC(name=\"pr_auc\", curve=\"PR\"),\n",
    "])\n",
    "\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0095c9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_cnn = cnn.fit(X_train_cnn, y_train, epochs=25, validation_data=(X_test_cnn, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7076ee7a",
   "metadata": {},
   "source": [
    "### Evaluate CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efadd0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_eval = cnn.evaluate(X_test_cnn, y_test, verbose=0)\n",
    "dict(zip(cnn.metrics_names, cnn_eval))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd761322",
   "metadata": {},
   "source": [
    "## Scoring + binning plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259a3834",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_bins(y_true, y_score, n_bins=10):\n",
    "    out = pd.DataFrame({\"y\": y_true, \"y_pred\": y_score})\n",
    "    out[\"score_cut\"] = pd.qcut(out[\"y_pred\"], q=n_bins, labels=list(range(n_bins)))\n",
    "    g = out.groupby(\"score_cut\")[[\"y_pred\", \"y\"]].mean().reset_index()\n",
    "    g[\"score_cut\"] = g[\"score_cut\"].astype(int)\n",
    "    g[\"score_cut\"] = n_bins - g[\"score_cut\"]\n",
    "    return out, g\n",
    "\n",
    "y_pred_ann = ann.predict(X_test, verbose=0).ravel()\n",
    "y_pred_cnn = cnn.predict(X_test_cnn, verbose=0).ravel()\n",
    "\n",
    "ann_df, ann_sum = score_bins(y_test, y_pred_ann, n_bins=10)\n",
    "cnn_df, cnn_sum = score_bins(y_test, y_pred_cnn, n_bins=10)\n",
    "\n",
    "fig = plt.figure(figsize=(12,5))\n",
    "sns.barplot(x=ann_sum[\"score_cut\"], y=ann_sum[\"y\"])\n",
    "plt.title(\"ANN: Actual Bad Rate by Score Decile (higher= riskier)\")\n",
    "plt.xlabel(\"Score Decile (1=highest)\")\n",
    "plt.ylabel(\"Actual bad rate\")\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(figsize=(12,5))\n",
    "sns.barplot(x=cnn_sum[\"score_cut\"], y=cnn_sum[\"y\"])\n",
    "plt.title(\"CNN: Actual Bad Rate by Score Decile (higher= riskier)\")\n",
    "plt.xlabel(\"Score Decile (1=highest)\")\n",
    "plt.ylabel(\"Actual bad rate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ae3846",
   "metadata": {},
   "source": [
    "## Combine scores (two simple composites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3c4261",
   "metadata": {},
   "outputs": [],
   "source": [
    "combo = pd.DataFrame({\n",
    "    \"y\": y_test,\n",
    "    \"y_pred_ann\": y_pred_ann,\n",
    "    \"y_pred_cnn\": y_pred_cnn,\n",
    "})\n",
    "\n",
    "# Approach 1: geometric mean (penalizes disagreement)\n",
    "combo[\"composite_geo\"] = np.sqrt(combo[\"y_pred_ann\"] * combo[\"y_pred_cnn\"])\n",
    "\n",
    "# Approach 2: simple mean\n",
    "combo[\"composite_mean\"] = (combo[\"y_pred_ann\"] + combo[\"y_pred_cnn\"]) / 2\n",
    "\n",
    "combo.corr(numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081a3fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in [\"composite_geo\", \"composite_mean\"]:\n",
    "    _, s = score_bins(combo[\"y\"].values, combo[col].values, n_bins=10)\n",
    "    plt.figure(figsize=(12,5))\n",
    "    sns.barplot(x=s[\"score_cut\"], y=s[\"y\"])\n",
    "    plt.title(f\"Composite ({col}): Actual Bad Rate by Score Decile\")\n",
    "    plt.xlabel(\"Score Decile (1=highest)\")\n",
    "    plt.ylabel(\"Actual bad rate\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2db7d1d",
   "metadata": {},
   "source": [
    "## Notes on evaluation\n",
    "\n",
    "Because the event rate is low (~2â€“3%), you should report:\n",
    "\n",
    "- ROC AUC\n",
    "- PR AUC\n",
    "- Confusion matrix at a chosen threshold (e.g., top 5% risk)\n",
    "- Lift / KS\n",
    "- Calibration (predicted vs actual)\n",
    "\n",
    "â€¦and choose thresholds based on business cost (false negatives vs false positives)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mortgage_risk_modeling)",
   "language": "python",
   "name": "mortgage_risk_modeling"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
