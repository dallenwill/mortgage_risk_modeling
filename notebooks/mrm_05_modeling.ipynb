{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdde1c31",
   "metadata": {},
   "source": [
    "# ðŸ§© Modeling: KMeans Segmentation\n",
    "\n",
    "Goal: segment loans into groups with potentially different risk profiles, then validate by comparing **bad rates** per cluster on a holdout set.\n",
    "\n",
    "> Note: KMeans uses Euclidean distance, so we use numeric, scaled features only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf68538",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04120870",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "This notebook expects a loan-level dataset with features + `bad`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552dcb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use df_model (wrangled) or df_fe (engineered) depending on your goal.\n",
    "# Here we follow the segmentation approach from your draft: origination + purpose/property dummies.\n",
    "\n",
    "# If not in memory, load from disk:\n",
    "# df_model = pd.read_parquet(DATA_DIR + \"df_model.parquet\")\n",
    "\n",
    "df_seg = df.copy()  # if you ran earlier notebooks in the same session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45bd6ca",
   "metadata": {},
   "source": [
    "## Prepare variables for clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019e50e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example variable list from your clustering draft\n",
    "df_seg[\"loan_term\"] = np.where(df_seg[\"ORIG_TERM\"] == 360, 2, np.where(df_seg[\"ORIG_TERM\"] == 180, 1, 0))\n",
    "\n",
    "# Exclude borrowers with invalid FICO\n",
    "df_seg = df_seg[df_seg[\"CSCORE_B\"] > 300].copy()\n",
    "\n",
    "# Collapse rare property types\n",
    "df_seg[\"prop\"] = np.where(df_seg[\"PROP\"].isin([\"MH\", \"CP\"]), \"other\", df_seg[\"PROP\"])\n",
    "\n",
    "# One-hot encode\n",
    "df_seg = pd.get_dummies(df_seg, columns=[\"PURPOSE\"])\n",
    "df_seg = pd.get_dummies(df_seg, columns=[\"prop\"])\n",
    "\n",
    "Xlist = [\n",
    "    \"ORIG_UPB\",\"CSCORE_B\",\"loan_term\",\"OLTV\",\"DTI\",\"NO_UNITS\",\"MI_PCT\",\n",
    "    \"PURPOSE_C\",\"PURPOSE_P\",\"PURPOSE_R\",\n",
    "    \"prop_CO\",\"prop_PU\",\"prop_SF\",\"prop_other\",\n",
    "]\n",
    "Xylist = Xlist + [\"bad\"]\n",
    "\n",
    "# split modeling vs validation\n",
    "df_seg[\"random\"] = np.random.uniform(0, 1, len(df_seg))\n",
    "df_seg[\"seg\"] = np.where(df_seg[\"random\"] <= 0.7, \"mod\", \"val\")\n",
    "\n",
    "modelsample = df_seg[df_seg[\"seg\"] == \"mod\"][Xylist].fillna(0).copy()\n",
    "valsample   = df_seg[df_seg[\"seg\"] == \"val\"][Xylist].fillna(0).copy()\n",
    "\n",
    "modelsample.shape, valsample.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de24036",
   "metadata": {},
   "source": [
    "## Scale features (fit on modeling sample, apply to validation)\n",
    "\n",
    "Your original draft standardizes then min-max scales. Below is a faithful version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1ec349",
   "metadata": {},
   "outputs": [],
   "source": [
    "modsamp = modelsample.copy()\n",
    "\n",
    "def standardize(col, samp, ref):\n",
    "    mu = ref[col].mean()\n",
    "    sd = ref[col].std()\n",
    "    return (samp[col] - mu) / (sd if sd != 0 else 1)\n",
    "\n",
    "for col in Xlist:\n",
    "    modelsample[col] = standardize(col, modelsample, modsamp)\n",
    "    valsample[col]   = standardize(col, valsample, modsamp)\n",
    "\n",
    "modsamp2 = modelsample.copy()\n",
    "\n",
    "def minmax(col, samp, ref):\n",
    "    mx = ref[col].max()\n",
    "    mn = ref[col].min()\n",
    "    denom = (mx - mn) if (mx - mn) != 0 else 1\n",
    "    return (samp[col] - mn) / denom\n",
    "\n",
    "for col in Xlist:\n",
    "    modelsample[col] = minmax(col, modelsample, modsamp2)\n",
    "    valsample[col]   = minmax(col, valsample, modsamp2)\n",
    "\n",
    "modelsample[Xlist].describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c692a788",
   "metadata": {},
   "source": [
    "## Choose K (elbow plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcb477b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "sse = []\n",
    "Ks = range(1, 15)\n",
    "X_mod = modelsample.drop(columns=[\"bad\"])\n",
    "\n",
    "for k in Ks:\n",
    "    km = KMeans(n_clusters=k, n_init=\"auto\", random_state=0)\n",
    "    km.fit(X_mod)\n",
    "    sse.append(km.inertia_)\n",
    "\n",
    "plt.plot(list(Ks), sse)\n",
    "plt.xlabel(\"K\")\n",
    "plt.ylabel(\"Sum of Squared Error (Inertia)\")\n",
    "plt.title(\"Elbow Plot for KMeans\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a06ae1",
   "metadata": {},
   "source": [
    "## Fit final KMeans + validate by bad rate per cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ec794a",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_final = 7\n",
    "km = KMeans(n_clusters=k_final, n_init=\"auto\", random_state=0)\n",
    "km.fit(X_mod)\n",
    "\n",
    "modelsample[\"cluster\"] = km.predict(X_mod)\n",
    "valsample[\"cluster\"]   = km.predict(valsample.drop(columns=[\"bad\"]))\n",
    "\n",
    "modelsum = modelsample.groupby(\"cluster\")[\"bad\"].agg(model_count=\"count\", model_sum=\"sum\", model_mean=\"mean\")\n",
    "modelsum[\"model_count_pct\"] = modelsum[\"model_count\"] / modelsum[\"model_count\"].sum()\n",
    "\n",
    "valsum = valsample.groupby(\"cluster\")[\"bad\"].agg(val_count=\"count\", val_sum=\"sum\", val_mean=\"mean\")\n",
    "valsum[\"val_count_pct\"] = valsum[\"val_count\"] / valsum[\"val_count\"].sum()\n",
    "\n",
    "mod_val_sum = pd.merge(modelsum, valsum, on=\"cluster\", how=\"outer\").reset_index()\n",
    "mod_val_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d936be9e",
   "metadata": {},
   "source": [
    "### Plot: bad rate by cluster (model vs validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da012a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = sorted(mod_val_sum[\"cluster\"].tolist())\n",
    "x_axis = np.arange(len(clusters))\n",
    "\n",
    "plt.bar(x_axis - 0.2, mod_val_sum[\"model_mean\"], width=0.4, label=\"modeling\")\n",
    "plt.bar(x_axis + 0.2, mod_val_sum[\"val_mean\"], width=0.4, label=\"validation\")\n",
    "plt.xticks(x_axis, clusters)\n",
    "plt.xlabel(\"Cluster\")\n",
    "plt.ylabel(\"Bad Rate\")\n",
    "plt.title(\"Bad Rate by Cluster (Model vs Validation)\")\n",
    "plt.gca().yaxis.set_major_formatter(lambda x, pos: f\"{x:.1%}\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f2778c",
   "metadata": {},
   "source": [
    "### Plot: borrower share by cluster (model vs validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555b5a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(x_axis - 0.2, mod_val_sum[\"model_count_pct\"], width=0.4, label=\"modeling\")\n",
    "plt.bar(x_axis + 0.2, mod_val_sum[\"val_count_pct\"], width=0.4, label=\"validation\")\n",
    "plt.xticks(x_axis, clusters)\n",
    "plt.xlabel(\"Cluster\")\n",
    "plt.ylabel(\"% Borrowers\")\n",
    "plt.title(\"Borrower Share by Cluster (Model vs Validation)\")\n",
    "plt.gca().yaxis.set_major_formatter(lambda x, pos: f\"{x:.1%}\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dsenv)",
   "language": "python",
   "name": "dsenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
